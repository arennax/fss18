{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Foundations of Software Science Fall 2018 NC State Computer Science Tuesdays, Thursdays, 4:30pm Prof. Tim Menzies Why? Here is a pressing question; The future of SE is more and more AI . But AI software is still software; So as society uses more AI, SE folks will be required to use and maintain and extend that software; So how should SE people look at AI software? What should they expect from that software? What would be an AI software \"bad smells\" that prompts a code reorganization? Enter this subject. What? How to teach software how to be a scientist Automatically build, critique, and revise models. How to build and modify and refactor and remix and repurpose: Software for data miners; Software for optimizers; Software for theorem provers. To help society, and our customers, achieve their dreams better, faster, and cheaper. How to achieve maximum AI benefits at minimal AI costs: By recognize and modify bias in learners. By reducing the CPU and memory footprints of AI; By respecting the privacy of citizens in a society shared with AI. How? Monthly: August = Start-up September = Data mining October = Optimizers and theorem provers November = Your do your own big project that utilizes the tools and perspectivs of this sibject. Weekly (till mid-October): Small, simple programming assignments Regular poster presentations by students on some tiny aspect of AI+SE For full details, see the syllabus .","title":"Hello"},{"location":"#foundations-of-software-science","text":"Fall 2018 NC State Computer Science Tuesdays, Thursdays, 4:30pm Prof. Tim Menzies","title":"Foundations of Software Science"},{"location":"#why","text":"Here is a pressing question; The future of SE is more and more AI . But AI software is still software; So as society uses more AI, SE folks will be required to use and maintain and extend that software; So how should SE people look at AI software? What should they expect from that software? What would be an AI software \"bad smells\" that prompts a code reorganization? Enter this subject.","title":"Why?"},{"location":"#what","text":"How to teach software how to be a scientist Automatically build, critique, and revise models. How to build and modify and refactor and remix and repurpose: Software for data miners; Software for optimizers; Software for theorem provers. To help society, and our customers, achieve their dreams better, faster, and cheaper. How to achieve maximum AI benefits at minimal AI costs: By recognize and modify bias in learners. By reducing the CPU and memory footprints of AI; By respecting the privacy of citizens in a society shared with AI.","title":"What?"},{"location":"#how","text":"Monthly: August = Start-up September = Data mining October = Optimizers and theorem provers November = Your do your own big project that utilizes the tools and perspectivs of this sibject. Weekly (till mid-October): Small, simple programming assignments Regular poster presentations by students on some tiny aspect of AI+SE For full details, see the syllabus .","title":"How?"},{"location":"about/","text":"Neque iam est venti flamma corpora aderam Consulit cunctae cruore inposuit Quis superi Lorem markdownum; si muta , iam vidi. Gravet crevit, afuerunt aetherias datus, gravitate utque; amnemque breve et excutiant . Scit vineta vincas dentes tympana. Imagine me mediis sequentis nati coloni illa distabat? Que sed creavit terreris flammaeque ipsos cornuaque ponto iugulo formaeque Seditioque naves sors temptanti. Servaberis Cererem alis, est sua his divam euntem, opemque. Debes vectus , ait, ordine , pallentemque valeant respicere, et ego. Hanc illo favilla promissis ut habenis Tritoniaca: sex ad matres habet , distinxit. Dum mens populos intrarant at genusque multaque Non fuit ipse, vim sed Erectheus sequitur: contra et corymbis. Cadit pars vitulus , erat anno inmiti momordit mihi, sparserat sacravere haut concussit miles. Puro una , est figura celer. Neque virum poterat Sunt studiumque audit iam Dubitat natus caret poteram suspicere Dea templis sede alimenta obscenique feroces vidit Eosdem mutata A pudori nemorum loquentem, si sic relicta, flammas violentaque matrem. Tamen omnia nec cernitis mugitus popularia paterno formas flava sed? Inferius haec et Alce sacerdos, imago unde dea ab tacitus dixi . redundancy_ccd_menu.fileWysiwygWpa(url, directory_floppy_meta - toggle, led( tiffToggleScrolling, printer)); tableTroubleshootingAlu(syntax, server_aiff); leopard_bios += c_jpeg(computing_unfriend_led(fileRosettaUp, winsock)); var dvdStationBluetooth = font(wiredDriver.hot_json_dithering(secondary, key, pim_bluetooth_bit) / 3); Visa fecit, esse Circes omnibus forma : Minervae expulit cum colat quiescere. Ignotis status mutatum, Haemus , videntur, femineo intrarunt de absunt iubentque turba inritamina suae. Quae neci non has aurigam plangorem quae, sensit frustra molitur laceri, alendi madidus quattuor. Romulus tum , qui non ab movent conligit Coronida, nostra; et.","title":"Neque iam est venti flamma corpora aderam"},{"location":"about/#neque-iam-est-venti-flamma-corpora-aderam","text":"","title":"Neque iam est venti flamma corpora aderam"},{"location":"about/#consulit-cunctae-cruore-inposuit-quis-superi","text":"Lorem markdownum; si muta , iam vidi. Gravet crevit, afuerunt aetherias datus, gravitate utque; amnemque breve et excutiant . Scit vineta vincas dentes tympana. Imagine me mediis sequentis nati coloni illa distabat? Que sed creavit terreris flammaeque ipsos cornuaque ponto iugulo formaeque Seditioque naves sors temptanti. Servaberis Cererem alis, est sua his divam euntem, opemque. Debes vectus , ait, ordine , pallentemque valeant respicere, et ego. Hanc illo favilla promissis ut habenis Tritoniaca: sex ad matres habet , distinxit.","title":"Consulit cunctae cruore inposuit Quis superi"},{"location":"about/#dum-mens-populos-intrarant-at-genusque-multaque","text":"Non fuit ipse, vim sed Erectheus sequitur: contra et corymbis. Cadit pars vitulus , erat anno inmiti momordit mihi, sparserat sacravere haut concussit miles. Puro una , est figura celer. Neque virum poterat Sunt studiumque audit iam Dubitat natus caret poteram suspicere Dea templis sede alimenta obscenique feroces vidit","title":"Dum mens populos intrarant at genusque multaque"},{"location":"about/#eosdem-mutata","text":"A pudori nemorum loquentem, si sic relicta, flammas violentaque matrem. Tamen omnia nec cernitis mugitus popularia paterno formas flava sed? Inferius haec et Alce sacerdos, imago unde dea ab tacitus dixi . redundancy_ccd_menu.fileWysiwygWpa(url, directory_floppy_meta - toggle, led( tiffToggleScrolling, printer)); tableTroubleshootingAlu(syntax, server_aiff); leopard_bios += c_jpeg(computing_unfriend_led(fileRosettaUp, winsock)); var dvdStationBluetooth = font(wiredDriver.hot_json_dithering(secondary, key, pim_bluetooth_bit) / 3); Visa fecit, esse Circes omnibus forma : Minervae expulit cum colat quiescere. Ignotis status mutatum, Haemus , videntur, femineo intrarunt de absunt iubentque turba inritamina suae. Quae neci non has aurigam plangorem quae, sensit frustra molitur laceri, alendi madidus quattuor. Romulus tum , qui non ab movent conligit Coronida, nostra; et.","title":"Eosdem mutata"},{"location":"history/","text":"SE + AI: then and now SE's past is full of cases where someone declared \"X\" was not part of SE then we ignored them and added \"X\" to SE and lots of things got lots better So the question I pose to you is this: Q: What is currently \"not\" SE, but soon must be? A: AI Enter this subject SE: the past e.g. \"SE is not about requirements engineering\" (which is wrong) e.g. From Boehm, Keynote, 2004 , slide 8: \"The notion of 'user' cannot be precisely defined, and therefore has no place in CS or SE.\" Edsger Dijkstra, ICSE 4, 1979 \"Analysis and allocation of the system requirements is not the responsibility of the SE group but is a prerequisite for their work.\" Mark Paulk at al., SEI Software CMM* v.1.1, 1993 e.g. \"Programmning is not about testing\" (wrong again) e.g. Harlin Mills, 1984 : software engineers should write, but not run or test, their own software \"Cleanroom software engineering\" No unit testing (instead, mathematical verification) so before we run anything, we write perfect code And there is a seperate testing team to the programming team e.g. \"Programming is not about deploying software\" (so very, very wrong) Before devops, the coding team used to hand off the system to the production team Now we do much less of that.. achieving must faster change cycles Q: So What's next? A: AI SE: the present Software now mediates what we see and how we act Chemists win Nobel Prize for software sims Engineers use software to design optical tweezers, radiation therapy, remote sensing, chip design Web analysts use software to analyze clickstreams to improve sales and marketing strategies Stock traders write software to simulate trading strategies Analysts write software to mine labor statistics data to review proposed gov policies Journalists use software to analyze economic data, make visualizations of their news stories Etc etc etc In short, now more than ever, software really really matters In London or New York, The time for ambulance to reach patient is controlled by models If you cross the border Arizona to Mexico, Models determine if you are taken away for extra security measures If you default on a car loans, Models determine when (or if) someone repossesses your car Autonomous cars Software is essential to international financial and transport systems; our energy generation and distribution systems; and even the pacemakers that control the beat of our hearts. Looking forward, to the forthcoming age of autonomous cars and flying drones, it is clear that software models (written in traditional programming languages or in some next-generation interpretation) will be key in determining what we can do, when, where, and how. So how can we help our AI systems reason better about our data, and our models? Using data mining, we might learn a model from data that predicts for (say) a single target class; Using optionzers, we might a multi-objective optimizer to find what solutions score best on multiple target variables. Also, data miners can be used to to summarize the data, after which optimizers can leap to better solutions, faster ; Also, optimizers can be used to select intelligent settings for data mining algorithms e.g. such as how many trees should be included in a random forest. SE: the future Software enginenering isn't just about software any more Olde SE: just polish up the lens of the telescope New SE (with AI): use the telescope to look and understand and change \"things\" After \"continuous integration\" (where we automated everything) Comes \"AI everywhere\" (where we automate automation). From Software Analytics: What\u2019s Next? , IEEE Software, Sept/Oct 2018: \"Consider the rise of the data scientist in industry. Many organizations now pay handsomely to hire large teams of data scientists. For example, at the time of this writing, there are more than 1,000 Microsoft employees exploring project data using software analytics. These teams are performing tasks that a decade ago would have been called cutting-edge research. But now we call that work standard operating procedure .\" \"Every innovation also offers new opportunities. There is a flow-on effect from software analytics to other AI tasks outside of software engineering. Software analytics lets software engineers learn about AI techniques, all the while practicing on domains they understand (i.e., their own development practices). Once developers can apply data-mining algorithms to their data, they can build and ship innovative AI tools. While sometimes those tools solve software engineering problems (e.g., recommending what to change in source code), they can also be used on a wider range of problems. That is, we see software analytics as the training ground for the next generation of AI-literate software engineers working on applications such as image recognition, large-scale text mining, autonomous cars, drones, etc.\" \"What is the most important technology newcomers should learn to make themselves better at data science (in general) and software analytics (in particular)? \"To answer this question, we need a workable definition of \u201cscience,\u201d which we take to mean a community of people collecting, curating, and critiquing a set of ideas. In this community, everyone does each other the courtesy to try to prove this shared pool of ideas. By this definition, most data science (and much software analytics) is not science. Many developers use software analytics tools to produce conclusions, and that\u2019s the end of the story. Those conclusions are not registered and monitored. There is nothing that checks whether old conclusions are now out of date (e.g., using anomaly detectors). There are no incremental revisions that seek minimal changes when updating old ideas. \"If software analytics really wants to be called a science, then it needs to be more than just a way to make conclusions about the present. Any scientist will tell you that all ideas should be checked, rechecked, and incrementally revised. Data science methods such as software analytics should be a tool for assisting in complex discussions about ongoing issues. Which is a long-winded way of saying that the technology we most need to better understand software analytics and data science is ... science.\"","title":"SE+AI,  then and now"},{"location":"history/#se-ai-then-and-now","text":"SE's past is full of cases where someone declared \"X\" was not part of SE then we ignored them and added \"X\" to SE and lots of things got lots better So the question I pose to you is this: Q: What is currently \"not\" SE, but soon must be? A: AI Enter this subject","title":"SE + AI: then and now"},{"location":"history/#se-the-past","text":"","title":"SE: the past"},{"location":"history/#eg-se-is-not-about-requirements-engineering-which-is-wrong","text":"e.g. From Boehm, Keynote, 2004 , slide 8: \"The notion of 'user' cannot be precisely defined, and therefore has no place in CS or SE.\" Edsger Dijkstra, ICSE 4, 1979 \"Analysis and allocation of the system requirements is not the responsibility of the SE group but is a prerequisite for their work.\" Mark Paulk at al., SEI Software CMM* v.1.1, 1993","title":"e.g. \"SE is not about requirements engineering\" (which is wrong)"},{"location":"history/#eg-programmning-is-not-about-testing-wrong-again","text":"e.g. Harlin Mills, 1984 : software engineers should write, but not run or test, their own software \"Cleanroom software engineering\" No unit testing (instead, mathematical verification) so before we run anything, we write perfect code And there is a seperate testing team to the programming team","title":"e.g. \"Programmning  is not about testing\" (wrong again)"},{"location":"history/#eg-programming-is-not-about-deploying-software-so-very-very-wrong","text":"Before devops, the coding team used to hand off the system to the production team Now we do much less of that.. achieving must faster change cycles","title":"e.g. \"Programming  is not about deploying software\"  (so very, very wrong)"},{"location":"history/#q-so-whats-next","text":"A: AI","title":"Q: So What's next?"},{"location":"history/#se-the-present","text":"Software now mediates what we see and how we act Chemists win Nobel Prize for software sims Engineers use software to design optical tweezers, radiation therapy, remote sensing, chip design Web analysts use software to analyze clickstreams to improve sales and marketing strategies Stock traders write software to simulate trading strategies Analysts write software to mine labor statistics data to review proposed gov policies Journalists use software to analyze economic data, make visualizations of their news stories Etc etc etc In short, now more than ever, software really really matters In London or New York, The time for ambulance to reach patient is controlled by models If you cross the border Arizona to Mexico, Models determine if you are taken away for extra security measures If you default on a car loans, Models determine when (or if) someone repossesses your car Autonomous cars Software is essential to international financial and transport systems; our energy generation and distribution systems; and even the pacemakers that control the beat of our hearts. Looking forward, to the forthcoming age of autonomous cars and flying drones, it is clear that software models (written in traditional programming languages or in some next-generation interpretation) will be key in determining what we can do, when, where, and how. So how can we help our AI systems reason better about our data, and our models? Using data mining, we might learn a model from data that predicts for (say) a single target class; Using optionzers, we might a multi-objective optimizer to find what solutions score best on multiple target variables. Also, data miners can be used to to summarize the data, after which optimizers can leap to better solutions, faster ; Also, optimizers can be used to select intelligent settings for data mining algorithms e.g. such as how many trees should be included in a random forest.","title":"SE: the present"},{"location":"history/#se-the-future","text":"Software enginenering isn't just about software any more Olde SE: just polish up the lens of the telescope New SE (with AI): use the telescope to look and understand and change \"things\" After \"continuous integration\" (where we automated everything) Comes \"AI everywhere\" (where we automate automation). From Software Analytics: What\u2019s Next? , IEEE Software, Sept/Oct 2018: \"Consider the rise of the data scientist in industry. Many organizations now pay handsomely to hire large teams of data scientists. For example, at the time of this writing, there are more than 1,000 Microsoft employees exploring project data using software analytics. These teams are performing tasks that a decade ago would have been called cutting-edge research. But now we call that work standard operating procedure .\" \"Every innovation also offers new opportunities. There is a flow-on effect from software analytics to other AI tasks outside of software engineering. Software analytics lets software engineers learn about AI techniques, all the while practicing on domains they understand (i.e., their own development practices). Once developers can apply data-mining algorithms to their data, they can build and ship innovative AI tools. While sometimes those tools solve software engineering problems (e.g., recommending what to change in source code), they can also be used on a wider range of problems. That is, we see software analytics as the training ground for the next generation of AI-literate software engineers working on applications such as image recognition, large-scale text mining, autonomous cars, drones, etc.\" \"What is the most important technology newcomers should learn to make themselves better at data science (in general) and software analytics (in particular)? \"To answer this question, we need a workable definition of \u201cscience,\u201d which we take to mean a community of people collecting, curating, and critiquing a set of ideas. In this community, everyone does each other the courtesy to try to prove this shared pool of ideas. By this definition, most data science (and much software analytics) is not science. Many developers use software analytics tools to produce conclusions, and that\u2019s the end of the story. Those conclusions are not registered and monitored. There is nothing that checks whether old conclusions are now out of date (e.g., using anomaly detectors). There are no incremental revisions that seek minimal changes when updating old ideas. \"If software analytics really wants to be called a science, then it needs to be more than just a way to make conclusions about the present. Any scientist will tell you that all ideas should be checked, rechecked, and incrementally revised. Data science methods such as software analytics should be a tool for assisting in complex discussions about ongoing issues. Which is a long-winded way of saying that the technology we most need to better understand software analytics and data science is ... science.\"","title":"SE: the future"},{"location":"inspiration/","text":"Inspiration Light the fire Learn why the world wags and what wags it Live for the surprise \u201cIf the world merely lived up to our wildest dreams, what a dull place it would be. Happily\u2026\u201d \u2013 Tim Menzies","title":"Inspiration"},{"location":"inspiration/#inspiration","text":"","title":"Inspiration"},{"location":"inspiration/#light-the-fire","text":"","title":"Light the fire"},{"location":"inspiration/#learn-why-the-world-wags-and-what-wags-it","text":"","title":"Learn why the world wags and what wags it"},{"location":"inspiration/#live-for-the-surprise","text":"\u201cIf the world merely lived up to our wildest dreams, what a dull place it would be. Happily\u2026\u201d \u2013 Tim Menzies","title":"Live for the surprise"},{"location":"license/","text":"License This work is licensed under a Creative Commons Attribution 4.0 International License You are free to: Share: copy and redistribute the material in any medium or format Adapt: remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. No additional restrictions: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. Notices: Notice: You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","title":"License"},{"location":"license/#license","text":"This work is licensed under a Creative Commons Attribution 4.0 International License You are free to: Share: copy and redistribute the material in any medium or format Adapt: remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. No additional restrictions: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. Notices: Notice: You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation. No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","title":"License"},{"location":"lectures/","text":"","title":"Home"},{"location":"lectures/baselines/","text":"Baseline for an \"Adequate\" AI What do uou want? Requirements of a Baseline Estimation Model. Extended from Sarro, TOSEM'18 : Be simple to describe, implement, and interpret. Be deterministic in its outcomes. Be applicable to mixed qualitative and quantitative data. Offer some explanatory information regarding the prediction by representing generalised properties of the underlying data. Have no parameters within the modelling process that require tuning. Be publicly available via a reference implementation and associated environment for execution. Generally be more accurate than a random guess or an estimate based purely on the distribution of the response variable. Be robust to different data splits and validation methods. Do not be expensive to apply. Offer comparable performance to standard methods. XXXX why simplicity . XXX what does explanatory mean XXX streaming XXX revising re stochasthic. Disagree stochastic = scalability, stability (shout stochastic you won't know if your re living in some some tiny island surrounded by forces of chaos) In some software engineering applications, solution robustness may be as im- portant as solution functionality. For example, it may be better to locate an area of the search space that is rich in fit solutions, rather than identifying an even better solution that is surrounded by a set of far less fit solutions. Hitherto, research on SBSE has tended to focus on the production of the fittest possible results. However, many application areas require solutions in a search space that may be subject to change. This makes robustness a natural second order property to which the research community could and should turn its at- tention [30]. M. Harman and B. Jones. Search-based software engineering. Journal of Information and Software Technology, 43:833\u2013839, December 2001. All Connected The more we compress the smaller the memory and the faster we learn and the less we need to share (so more privacy). The more we understand the data's prototypes the more we know what is usual/ unusual so we more we know what is anomlaous so the easier it is to ofer a certification envelope Note that if our compression method is somehow hierarhical and if we track the errors seen by our learners in different subtrees then the more we know which parts of the model need revising (and which can stay the same). Which means we only make revisions to the parts that matter, elaving the rest stable. Other Requirements No eval tools Tests conclusion stability across mulitple data sets (if avaialable) or across multiple subsets of know scenarios See Evalaution for many examples of that kind of evaluation. Note that these can significantly increase the computational cost of using learners. Hence, the need to faster , lighter AI algorithms. No stats tests Check if this treatment has same effect as that treatment. Need at least two tests: significance and effect size I also think you need a third test; Something that clusters the treatments before the other tests are applied Reduces the number of other statistical tests. E.g the Scott-Knot test.","title":"Bad Smells for AI"},{"location":"lectures/baselines/#baseline-for-an-adequate-ai","text":"","title":"Baseline for an \"Adequate\" AI"},{"location":"lectures/baselines/#what-do-uou-want","text":"Requirements of a Baseline Estimation Model. Extended from Sarro, TOSEM'18 : Be simple to describe, implement, and interpret. Be deterministic in its outcomes. Be applicable to mixed qualitative and quantitative data. Offer some explanatory information regarding the prediction by representing generalised properties of the underlying data. Have no parameters within the modelling process that require tuning. Be publicly available via a reference implementation and associated environment for execution. Generally be more accurate than a random guess or an estimate based purely on the distribution of the response variable. Be robust to different data splits and validation methods. Do not be expensive to apply. Offer comparable performance to standard methods. XXXX why simplicity . XXX what does explanatory mean XXX streaming XXX revising re stochasthic. Disagree stochastic = scalability, stability (shout stochastic you won't know if your re living in some some tiny island surrounded by forces of chaos) In some software engineering applications, solution robustness may be as im- portant as solution functionality. For example, it may be better to locate an area of the search space that is rich in fit solutions, rather than identifying an even better solution that is surrounded by a set of far less fit solutions. Hitherto, research on SBSE has tended to focus on the production of the fittest possible results. However, many application areas require solutions in a search space that may be subject to change. This makes robustness a natural second order property to which the research community could and should turn its at- tention [30]. M. Harman and B. Jones. Search-based software engineering. Journal of Information and Software Technology, 43:833\u2013839, December 2001.","title":"What do uou want?"},{"location":"lectures/baselines/#all-connected","text":"The more we compress the smaller the memory and the faster we learn and the less we need to share (so more privacy). The more we understand the data's prototypes the more we know what is usual/ unusual so we more we know what is anomlaous so the easier it is to ofer a certification envelope Note that if our compression method is somehow hierarhical and if we track the errors seen by our learners in different subtrees then the more we know which parts of the model need revising (and which can stay the same). Which means we only make revisions to the parts that matter, elaving the rest stable.","title":"All Connected"},{"location":"lectures/baselines/#other-requirements","text":"","title":"Other Requirements"},{"location":"lectures/baselines/#no-eval-tools","text":"Tests conclusion stability across mulitple data sets (if avaialable) or across multiple subsets of know scenarios See Evalaution for many examples of that kind of evaluation. Note that these can significantly increase the computational cost of using learners. Hence, the need to faster , lighter AI algorithms.","title":"No eval tools"},{"location":"lectures/baselines/#no-stats-tests","text":"Check if this treatment has same effect as that treatment. Need at least two tests: significance and effect size I also think you need a third test; Something that clusters the treatments before the other tests are applied Reduces the number of other statistical tests. E.g the Scott-Knot test.","title":"No stats tests"},{"location":"lectures/eval/","text":"Evaluation Re-run on Multiple Samples e.g. cross-val Divide into \" x bins Test on one bin, train on the others Runs the risk of using future data to train for testing on the past Using combined with some stochastic re-orderings So \" M \" times, randomly rarrange order of data Then do an \" N \"-way cross val for each order Avoids \"order effects\" where the results are some quirky result based on the order of data colelction/generation. M=N=10 is common but I've never seen the point for more than M=N=5. e.g. round robin Given N projects Train on N-1, test on the nth. e.g Github issue close time, Table4 e.g. incremental validation. Divide into \" x \" buckets, Train on buckets 1..i, test on i+1 e.g. moving validation. Divide into \" x \" buckets, learn on buckets i..i+n, test on i+n+1. eg. Krishna's K-test. e.g. RRS (repeated random streaming) e.g. repeatedly stream over the data, each time using n% of the data selected at random Q: What \"n\"? A: Engineering judgement BTW, Beyond \"Evaluation\" Evaluation can be so tedious and time-consuming that many researchers have asked if all that inference can be applied to improving the model: So \"evaluation\" becomes \"improvement\" or \"monitor and repair\" Cross val to ensembles to bagging to boosting Round robin to transfer learning Anomaly detection to repair Incremental learning SAWTOOTH: Dumb as all hell Active learning uncertainty sampling certainty sampling Bayesian Parameter optimization (widely used) FLASH","title":"Evaluation"},{"location":"lectures/eval/#evaluation","text":"","title":"Evaluation"},{"location":"lectures/eval/#re-run-on-multiple-samples","text":"","title":"Re-run on Multiple Samples"},{"location":"lectures/eval/#eg-cross-val","text":"Divide into \" x bins Test on one bin, train on the others Runs the risk of using future data to train for testing on the past Using combined with some stochastic re-orderings So \" M \" times, randomly rarrange order of data Then do an \" N \"-way cross val for each order Avoids \"order effects\" where the results are some quirky result based on the order of data colelction/generation. M=N=10 is common but I've never seen the point for more than M=N=5.","title":"e.g. cross-val"},{"location":"lectures/eval/#eg-round-robin","text":"Given N projects Train on N-1, test on the nth. e.g Github issue close time, Table4","title":"e.g. round robin"},{"location":"lectures/eval/#eg-incremental-validation","text":"Divide into \" x \" buckets, Train on buckets 1..i, test on i+1","title":"e.g. incremental validation."},{"location":"lectures/eval/#eg-moving-validation","text":"Divide into \" x \" buckets, learn on buckets i..i+n, test on i+n+1. eg. Krishna's K-test.","title":"e.g. moving validation."},{"location":"lectures/eval/#eg-rrs-repeated-random-streaming","text":"e.g. repeatedly stream over the data, each time using n% of the data selected at random Q: What \"n\"? A: Engineering judgement","title":"e.g. RRS (repeated random streaming)"},{"location":"lectures/eval/#btw-beyond-evaluation","text":"Evaluation can be so tedious and time-consuming that many researchers have asked if all that inference can be applied to improving the model: So \"evaluation\" becomes \"improvement\" or \"monitor and repair\" Cross val to ensembles to bagging to boosting Round robin to transfer learning Anomaly detection to repair","title":"BTW, Beyond \"Evaluation\""},{"location":"lectures/eval/#incremental-learning","text":"SAWTOOTH: Dumb as all hell Active learning uncertainty sampling certainty sampling Bayesian Parameter optimization (widely used) FLASH","title":"Incremental learning"},{"location":"lectures/explain/","text":"Explain from the fse fft paper from the swan paper from the EMSE paper","title":"Explanation"},{"location":"lectures/explain/#explain","text":"from the fse fft paper from the swan paper from the EMSE paper","title":"Explain"},{"location":"lectures/simple/","text":"Simple. Please. Less complexity in the analysis: less CPU less cost (local hardware, cloud services) less energy consumption support the edge less pollution creating that energy simpler explanation simpler customization quicker more effective training easier experimentation easier reproducibility solutions more trustable because we need a baseline cause its just good science less CPU getting out of hand The mark Harman paper wei-style inference: $1,100,000 for 5 students for 3 years zhea : 3 years of CPU/day less cost (local hardware, cloud services) less energy consumption support the edge less pollution creating that energy simpler explanation simpler customization quicker more effective training easier experimentation easier reproducibility solutions more trustable because we need a baseline cause its just good science","title":"Simplicity"},{"location":"lectures/simple/#simple-please","text":"Less complexity in the analysis: less CPU less cost (local hardware, cloud services) less energy consumption support the edge less pollution creating that energy simpler explanation simpler customization quicker more effective training easier experimentation easier reproducibility solutions more trustable because we need a baseline cause its just good science","title":"Simple. Please."},{"location":"lectures/simple/#less-cpu","text":"getting out of hand The mark Harman paper wei-style inference: $1,100,000 for 5 students for 3 years zhea : 3 years of CPU/day","title":"less CPU"},{"location":"lectures/simple/#less-cost-local-hardware-cloud-services","text":"","title":"less cost (local hardware, cloud services)"},{"location":"lectures/simple/#less-energy-consumption","text":"","title":"less energy consumption"},{"location":"lectures/simple/#support-the-edge","text":"","title":"support the edge"},{"location":"lectures/simple/#less-pollution-creating-that-energy","text":"","title":"less pollution creating that energy"},{"location":"lectures/simple/#simpler-explanation","text":"","title":"simpler explanation"},{"location":"lectures/simple/#simpler-customization","text":"","title":"simpler customization"},{"location":"lectures/simple/#quicker-more-effective-training","text":"","title":"quicker more effective training"},{"location":"lectures/simple/#easier-experimentation","text":"","title":"easier experimentation"},{"location":"lectures/simple/#easier-reproducibility","text":"","title":"easier reproducibility"},{"location":"lectures/simple/#solutions-more-trustable","text":"","title":"solutions more trustable"},{"location":"lectures/simple/#because-we-need-a-baseline","text":"","title":"because we need a baseline"},{"location":"lectures/simple/#cause-its-just-good-science","text":"","title":"cause its just good science"},{"location":"proj/w1/","text":"Homework Week1, Week2 Todo Create a private Github repo (in public Github) Add \"timm\" as a team member to that repo. How? go the repo's organization's settings on left-hand-side menu go to Collaberators and teams then Enter \"timm\" under \"Collaborators\". Start a file with the following header (containing class O ). For Week1, address the Python101 task. For Week2, address the Table reader task. Commit the code (w1.py, w2.py) and a transcript of the output (called w1.txt, w2.txt) to a sub-directory in your repo called w12 . Paste a link to that directory in the commit sheet. A Simple Unit Test (in Python) import re,traceback class O: y=n=0 @staticmethod def report(): print( \\n# pass= %s fail= %s %%pass = %s%% % ( O.y,O.n, int(round(O.y*100/(O.y+O.n+0.001))))) @staticmethod def k(f): try: print( \\n-----| %s |----------------------- % f.__name__) if f.__doc__: print( # + re.sub(r'\\n[ \\t]*', \\n# ,f.__doc__)) f() print( # pass ) O.y += 1 except: O.n += 1 print(traceback.format_exc()) return f Test rig, in action Functions are called as a side-effect of load the file. The function comment is something the above rig prints out. If assertions fail, it prints the error but keeps on going to run the other tests. @O.k def testingFailure(): this one must fail.. just to test if the unit test system is working assert 1==2 @O.k def testingSuccess(): if this one fails, we have a problem! assert 1==1 if __name__== __main__ : O.report() For example, if you load this file with python3 thisfile.py you will see -----| testingFailure |----------------------- # this one must fail.. just to # test if the unit test system is working Traceback (most recent call last): File \"w1.py\", line 29, in k f() File \"w1.py\", line 52, in testingFailure assert 1==2 AssertionError -----| testingSuccess |----------------------- # if this one fails, we have a problem! # pass # pass= 1 fail= 1 %pass = 50% Note the last line (number of passes and failes in the code). Task1: Python101 Read Basic Python Write 27 functions like testingSuccess (above) that demonstrate you understand that the code on pages 5 to 33, skipping p21 (so one function for one thing on each page). Task2: Sample Table Data (that we want to read) Suppose we need to read in a table. DATA1 = outlook,$temp,?humidity,windy,play sunny,85,85,FALSE,no sunny,80,90,TRUE,no overcast,83,86,FALSE,yes rainy,70,96,FALSE,yes rainy,68,80,FALSE,yes rainy,65,70,TRUE,no overcast,64,65,TRUE,yes sunny,72,95,FALSE,no sunny,69,70,FALSE,yes rainy,75,80,FALSE,yes sunny,75,70,TRUE,yes overcast,100,25,90,TRUE,yes overcast,81,75,FALSE,yes rainy,71,91,TRUE,no Then we need to learn the type of the data (on row1) which in this case is numeric (if name has \" $ \"); ignrore this column (if name has \" \"); string, otherwise. And some tables of data are more challenging that others. Here's one where there are comments (after a \" # \"); rows can continue onto the next line (if they end in \",\"); there can be blank lines in the file DATA2 = outlook, # weather forecast. $temp, # degrees farenheit ?humidity, # relative humidity windy, # wind is high play # yes,no sunny,85,85,FALSE,no sunny,80,90,TRUE,no overcast,83,86,FALSE,yes rainy,70,96,FALSE,yes rainy,68,80,FALSE,yes rainy,65,70,TRUE,no overcast,64, 65,TRUE,yes sunny,72,95,FALSE,no sunny,69,70,FALSE,yes rainy,75,80,FALSE,yes sunny, 75,70,TRUE,yes overcast,100,25,90,TRUE,yes overcast,81,75,FALSE,yes # unique day rainy,71,91,TRUE,no Regardless of those details, when we read both these strings, we see as output ['outlook', '$temp', 'windy', 'play'] ['sunny', 85.0, 'FALSE', 'no'] ['sunny', 80.0, 'TRUE', 'no'] ['overcast', 83.0, 'FALSE', 'yes'] ['rainy', 70.0, 'FALSE', 'yes'] ['rainy', 68.0, 'FALSE', 'yes'] ['rainy', 65.0, 'TRUE', 'no'] ['overcast', 64.0, 'TRUE', 'yes'] ['sunny', 72.0, 'FALSE', 'no'] ['sunny', 69.0, 'FALSE', 'yes'] ['rainy', 75.0, 'FALSE', 'yes'] ['sunny', 75.0, 'TRUE', 'yes'] ['overcast', 100.0, '90', 'TRUE'] ['overcast', 81.0, 'FALSE', 'yes'] ['rainy', 71.0, 'TRUE', 'no'] Functions The following functions implement the table reader. def lines(s): Return contents, one line at a time. if s[-3:] in [ csv , dat ]: with open(s) as fs: for line in fs: yield line else: for line in s.splitlines(): yield line def rows(src): Kill bad characters. If line ends in ',' then join to next. Skip blank lines. cache = [] for line in src: line = re.sub(r'([ \\n\\r\\t]|#.*)', , line) cache += [line] if len(line) 0: if line[-1] != , : line = ''.join(cache) cache=[] yield line def cols(src, uses=None): If a column name on row1 contains '?', then skip over that column. for row in src: cells = row.split( , ) uses = uses or [False if ? in s[0] else True for s in cells] out = [cells[pos] for pos,use in enumerate(uses) if use] yield out def prep(src, nums=None): If a column name on row1 contains '$', coerce strings in that column to a float. for xs in src: if nums: xs= [(float(x) if num else x) for x,num in zip(xs,nums)] else: nums = [ $ in x[0] for x in xs] yield xs Test cases def ok0(s): for row in prep(cols(rows(lines(s)))): print(row) @O.k def ok1(): ok0(DATA1) @O.k def ok2(): ok0(DATA2)","title":"One"},{"location":"proj/w1/#homework-week1-week2","text":"","title":"Homework Week1, Week2"},{"location":"proj/w1/#todo","text":"Create a private Github repo (in public Github) Add \"timm\" as a team member to that repo. How? go the repo's organization's settings on left-hand-side menu go to Collaberators and teams then Enter \"timm\" under \"Collaborators\". Start a file with the following header (containing class O ). For Week1, address the Python101 task. For Week2, address the Table reader task. Commit the code (w1.py, w2.py) and a transcript of the output (called w1.txt, w2.txt) to a sub-directory in your repo called w12 . Paste a link to that directory in the commit sheet.","title":"Todo"},{"location":"proj/w1/#a-simple-unit-test-in-python","text":"import re,traceback class O: y=n=0 @staticmethod def report(): print( \\n# pass= %s fail= %s %%pass = %s%% % ( O.y,O.n, int(round(O.y*100/(O.y+O.n+0.001))))) @staticmethod def k(f): try: print( \\n-----| %s |----------------------- % f.__name__) if f.__doc__: print( # + re.sub(r'\\n[ \\t]*', \\n# ,f.__doc__)) f() print( # pass ) O.y += 1 except: O.n += 1 print(traceback.format_exc()) return f","title":"A Simple Unit Test (in Python)"},{"location":"proj/w1/#test-rig-in-action","text":"Functions are called as a side-effect of load the file. The function comment is something the above rig prints out. If assertions fail, it prints the error but keeps on going to run the other tests. @O.k def testingFailure(): this one must fail.. just to test if the unit test system is working assert 1==2 @O.k def testingSuccess(): if this one fails, we have a problem! assert 1==1 if __name__== __main__ : O.report() For example, if you load this file with python3 thisfile.py you will see -----| testingFailure |----------------------- # this one must fail.. just to # test if the unit test system is working Traceback (most recent call last): File \"w1.py\", line 29, in k f() File \"w1.py\", line 52, in testingFailure assert 1==2 AssertionError -----| testingSuccess |----------------------- # if this one fails, we have a problem! # pass # pass= 1 fail= 1 %pass = 50% Note the last line (number of passes and failes in the code).","title":"Test rig, in action"},{"location":"proj/w1/#task1-python101","text":"Read Basic Python Write 27 functions like testingSuccess (above) that demonstrate you understand that the code on pages 5 to 33, skipping p21 (so one function for one thing on each page).","title":"Task1: Python101"},{"location":"proj/w1/#task2-sample-table-data-that-we-want-to-read","text":"Suppose we need to read in a table. DATA1 = outlook,$temp,?humidity,windy,play sunny,85,85,FALSE,no sunny,80,90,TRUE,no overcast,83,86,FALSE,yes rainy,70,96,FALSE,yes rainy,68,80,FALSE,yes rainy,65,70,TRUE,no overcast,64,65,TRUE,yes sunny,72,95,FALSE,no sunny,69,70,FALSE,yes rainy,75,80,FALSE,yes sunny,75,70,TRUE,yes overcast,100,25,90,TRUE,yes overcast,81,75,FALSE,yes rainy,71,91,TRUE,no Then we need to learn the type of the data (on row1) which in this case is numeric (if name has \" $ \"); ignrore this column (if name has \" \"); string, otherwise. And some tables of data are more challenging that others. Here's one where there are comments (after a \" # \"); rows can continue onto the next line (if they end in \",\"); there can be blank lines in the file DATA2 = outlook, # weather forecast. $temp, # degrees farenheit ?humidity, # relative humidity windy, # wind is high play # yes,no sunny,85,85,FALSE,no sunny,80,90,TRUE,no overcast,83,86,FALSE,yes rainy,70,96,FALSE,yes rainy,68,80,FALSE,yes rainy,65,70,TRUE,no overcast,64, 65,TRUE,yes sunny,72,95,FALSE,no sunny,69,70,FALSE,yes rainy,75,80,FALSE,yes sunny, 75,70,TRUE,yes overcast,100,25,90,TRUE,yes overcast,81,75,FALSE,yes # unique day rainy,71,91,TRUE,no Regardless of those details, when we read both these strings, we see as output ['outlook', '$temp', 'windy', 'play'] ['sunny', 85.0, 'FALSE', 'no'] ['sunny', 80.0, 'TRUE', 'no'] ['overcast', 83.0, 'FALSE', 'yes'] ['rainy', 70.0, 'FALSE', 'yes'] ['rainy', 68.0, 'FALSE', 'yes'] ['rainy', 65.0, 'TRUE', 'no'] ['overcast', 64.0, 'TRUE', 'yes'] ['sunny', 72.0, 'FALSE', 'no'] ['sunny', 69.0, 'FALSE', 'yes'] ['rainy', 75.0, 'FALSE', 'yes'] ['sunny', 75.0, 'TRUE', 'yes'] ['overcast', 100.0, '90', 'TRUE'] ['overcast', 81.0, 'FALSE', 'yes'] ['rainy', 71.0, 'TRUE', 'no']","title":"Task2: Sample Table Data (that we want to read)"},{"location":"proj/w1/#functions","text":"The following functions implement the table reader. def lines(s): Return contents, one line at a time. if s[-3:] in [ csv , dat ]: with open(s) as fs: for line in fs: yield line else: for line in s.splitlines(): yield line def rows(src): Kill bad characters. If line ends in ',' then join to next. Skip blank lines. cache = [] for line in src: line = re.sub(r'([ \\n\\r\\t]|#.*)', , line) cache += [line] if len(line) 0: if line[-1] != , : line = ''.join(cache) cache=[] yield line def cols(src, uses=None): If a column name on row1 contains '?', then skip over that column. for row in src: cells = row.split( , ) uses = uses or [False if ? in s[0] else True for s in cells] out = [cells[pos] for pos,use in enumerate(uses) if use] yield out def prep(src, nums=None): If a column name on row1 contains '$', coerce strings in that column to a float. for xs in src: if nums: xs= [(float(x) if num else x) for x,num in zip(xs,nums)] else: nums = [ $ in x[0] for x in xs] yield xs","title":"Functions"},{"location":"proj/w1/#test-cases","text":"def ok0(s): for row in prep(cols(rows(lines(s)))): print(row) @O.k def ok1(): ok0(DATA1) @O.k def ok2(): ok0(DATA2)","title":"Test cases"}]}